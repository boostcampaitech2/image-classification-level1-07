{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e26d4356-5e44-49b5-804a-003d93394ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, CenterCrop, Normalize, ToPILImage, RandomHorizontalFlip\n",
    "from torchvision.transforms.functional import crop\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2f81e8e-bd41-4a34-94ba-3cf56d440b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3371fb1e-35a8-40c2-97dd-ef3f458dfa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "train_image_dir = os.path.join(train_dir, 'images')\n",
    "train_info = pd.read_csv(os.path.join(train_dir, 'train_labeled.csv'))\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "test_image_dir = os.path.join(test_dir, 'images')\n",
    "test_image_paths = [os.path.join(test_image_dir, img_id) for img_id in submission.ImageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7b006d1-51d6-4d16-a895-75c840fd5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_num = train_info[train_info['stem']=='.ipynb_checkpoints'].index\n",
    "train_info = train_info.drop(idx_num)\n",
    "\n",
    "train_image = list(train_info['img_path'])\n",
    "train_label = list(train_info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b422f573-a67f-4ef7-ab41-2a28a9bd6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(train_image[2554])\n",
    "# image = T.functional.crop(image, 128,96,256,192)\n",
    "# display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "efb4760f-12b2-4b15-8fdb-525e285d6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender 클래스와 age 클래스 수치화\n",
    "# gender_list = []\n",
    "# for each_gender in train_info['gender']:\n",
    "#     if each_gender=='male':\n",
    "#         gender_list.append(0)\n",
    "#     else:\n",
    "#         gender_list.append(1)\n",
    "# train_info['gender']=pd.Series(gender_list)\n",
    "# age_list = []\n",
    "# for each_age in train_info['age']:\n",
    "#     if each_age<30:\n",
    "#         age_list.append(0)\n",
    "#     elif 30<=each_age<60:\n",
    "#         age_list.append(1)\n",
    "#     else:\n",
    "#         age_list.append(2)\n",
    "# train_info['age']=pd.Series(age_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f0c23ab-3da2-4075-9717-20459e74c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train_image 리스트에는 각 사진들의 path가 담기고, train_label에는 각 사람의 클래스 정보가 담김(0~17)\n",
    "# train_image = []\n",
    "# train_label = []\n",
    "# for idx in range(len(train_info['id'])):\n",
    "#     id, gender, race, age, path = train_info.iloc[idx]\n",
    "#     root = os.path.join(train_image_dir, path)\n",
    "#     dirpath, dirnames, filenames = next(os.walk(root))\n",
    "#     for name in filenames:\n",
    "#         if name[0]=='i':\n",
    "#             label = 0\n",
    "#         elif name[0]=='m':\n",
    "#             label = 1\n",
    "#         elif name[0]=='n':\n",
    "#             label = 2\n",
    "#         else:\n",
    "#             continue\n",
    "#         train_image.append(os.path.join(root, name))\n",
    "#         train_label.append((label, gender, age))\n",
    "# for idx in range(len(train_label)):\n",
    "#     if train_label[idx]==(1,0,0):\n",
    "#         train_label[idx]=0\n",
    "#     elif train_label[idx]==(1,0,1):\n",
    "#         train_label[idx]=1\n",
    "#     elif train_label[idx]==(1,0,2):\n",
    "#         train_label[idx]=2\n",
    "#     elif train_label[idx]==(1,1,0):\n",
    "#         train_label[idx]=3\n",
    "#     elif train_label[idx]==(1,1,1):\n",
    "#         train_label[idx]=4\n",
    "#     elif train_label[idx]==(1,1,2):\n",
    "#         train_label[idx]=5\n",
    "#     elif train_label[idx]==(0,0,0):\n",
    "#         train_label[idx]=6\n",
    "#     elif train_label[idx]==(0,0,1):\n",
    "#         train_label[idx]=7\n",
    "#     elif train_label[idx]==(0,0,2):\n",
    "#         train_label[idx]=8\n",
    "#     elif train_label[idx]==(0,1,0):\n",
    "#         train_label[idx]=9\n",
    "#     elif train_label[idx]==(0,1,1):\n",
    "#         train_label[idx]=10\n",
    "#     elif train_label[idx]==(0,1,2):\n",
    "#         train_label[idx]=11\n",
    "#     elif train_label[idx]==(2,0,0):\n",
    "#         train_label[idx]=12\n",
    "#     elif train_label[idx]==(2,0,1):\n",
    "#         train_label[idx]=13\n",
    "#     elif train_label[idx]==(2,0,2):\n",
    "#         train_label[idx]=14\n",
    "#     elif train_label[idx]==(2,1,0):\n",
    "#         train_label[idx]=15\n",
    "#     elif train_label[idx]==(2,1,1):\n",
    "#         train_label[idx]=16\n",
    "#     elif train_label[idx]==(2,1,2):\n",
    "#         train_label[idx]=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe3e5c9a-77d7-49bb-92e6-803b87924da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.CenterCrop(224), \n",
    "                       T.ToTensor(), \n",
    "                       T.Normalize(mean=(0.55800916,0.51224077,0.47767341), std=(0.21817792,0.23804603,0.25183411))\n",
    "                      ])\n",
    "transform_weak = T.Compose([T.CenterCrop(224),  \n",
    "                            T.RandomHorizontalFlip(p=0.5), \n",
    "                            T.RandomRotation(degrees=(-30, 30)),  \n",
    "                            T.ToTensor(), \n",
    "                            T.Normalize(mean=(0.55800916,0.51224077,0.47767341), std=(0.21817792,0.23804603,0.25183411))\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "326e686e-1d4d-4fa0-b080-60738436108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, label, transform, transform_weak, weak_flag = True):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.transform_weak = transform_weak\n",
    "        self.label = label\n",
    "        self.classes = pd.Series(self.label).unique()\n",
    "        self.weak_flag = weak_flag\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        y = self.label[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            if self.weak_flag:\n",
    "                if y in [2,5,6,7,8,9,10,11,12,13,14,15,16,17]:\n",
    "                    image = self.transform_weak(image)\n",
    "                else:\n",
    "                    image = self.transform(image)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "        return image, torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19f8b56b-5486-4587-a5d2-3bef5165479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        #image = T.functional.crop(image, 128,96,256,192)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f638a2d5-17e3-41a7-9e08-b0a2232bec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "image_train, image_valid, label_train, label_valid = train_test_split(train_image, train_label, train_size=0.8, shuffle=True, random_state=random_seed, stratify=train_label)\n",
    "Dataset_Train = TrainDataset(img_paths = image_train, label = label_train, transform = transform, transform_weak = transform_weak, weak_flag = True)\n",
    "Dataset_Valid = TrainDataset(img_paths = image_valid, label = label_valid, transform = transform, transform_weak = transform_weak, weak_flag = False)\n",
    "Dataset_Test = TestDataset(img_paths = test_image_paths, transform = transform)\n",
    "# Dataset_Train = TrainDataset(img_paths = train_image, label = train_label, transform = transform)\n",
    "# Dataset_Test = TestDataset(img_paths = test_image_paths, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13df4c0d-ea22-4e94-a3e1-0a9b67ce31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SmoothCrossEntropy(nn.Module):\n",
    "#     def __init__(self, alpha=0.1):\n",
    "#         super(SmoothCrossEntropy, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "\n",
    "#     def forward(self, logits, labels):\n",
    "#         num_classes = logits.shape[-1]\n",
    "#         alpha_div_k = self.alpha / num_classes\n",
    "#         target_probs = F.one_hot(labels, num_classes=num_classes).float() * \\\n",
    "#             (1. - self.alpha) + alpha_div_k\n",
    "#         loss = -(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)\n",
    "#         return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "468b55fb-bed0-45c9-b1d8-939bc8b9c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model_name = 'vit_tiny_patch16_224'\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=18).to(device)\n",
    "#model.head = nn.Sequential(nn.Linear(in_features=192, out_features=18, bias=True), nn.Dropout(0.1))\n",
    "#model.to(device)\n",
    "best_model_state = None\n",
    "early_stop = 8\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "class_num = [2745, 2050, 415, 3660, 4085, 545, 549, 410, 83, 732, 817, 109, 549, 410, 83, 732, 817, 109]\n",
    "class_weight = torch.tensor(np.max(class_num) / class_num).to(device=device, dtype=torch.float)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "\n",
    "feature_extractor = [m for n, m in model.named_parameters() if \"head\" not in n]\n",
    "classifier = [p for p in model.head.parameters()]\n",
    "params = [\n",
    "    {\"params\": feature_extractor, \"lr\": learning_rate * 0.2},\n",
    "    {\"params\": classifier, \"lr\": learning_rate}\n",
    "]\n",
    "optimizer = optim.AdamW(params, lr=learning_rate)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in model.head.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "\n",
    "batch_size = 64\n",
    "# dataloaders_train = DataLoader(dataset=Dataset_Train, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(0, len(Dataset_Train) * 4//5)), num_workers = 2)\n",
    "# dataloaders_valid = DataLoader(dataset=Dataset_Train, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(len(Dataset_Train) * 4//5, len(Dataset_Train))), num_workers = 2)\n",
    "dataloaders_train = DataLoader(dataset=Dataset_Train, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "dataloaders_valid = DataLoader(dataset=Dataset_Valid, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "dataloaders_test = DataLoader(Dataset_Test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72e69072-62b5-4d48-a91a-7d12ba28fb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=192, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f231fc0-1a71-4cff-ab87-32829e26d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 0 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [01:00,  3.92it/s]\n",
      "60it [00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train loss : 0.9958 | train acc : 72.67% valid loss : 0.8284 | valid acc : 79.95% | valid f1 score : 0.6444\n",
      "*** Epoch 1 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  4.00it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss : 0.4724 | train acc : 88.23% valid loss : 1.0402 | valid acc : 84.07% | valid f1 score : 0.6779\n",
      "*** Epoch 2 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.95it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss : 0.3109 | train acc : 92.28% valid loss : 1.3780 | valid acc : 80.82% | valid f1 score : 0.6061\n",
      "*** Epoch 3 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.95it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss : 0.2582 | train acc : 94.13% valid loss : 1.4975 | valid acc : 77.88% | valid f1 score : 0.5700\n",
      "*** Epoch 4 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.97it/s]\n",
      "60it [00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train loss : 0.1697 | train acc : 96.06% valid loss : 1.2477 | valid acc : 83.54% | valid f1 score : 0.6506\n",
      "*** Epoch 5 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.94it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train loss : 0.1333 | train acc : 97.11% valid loss : 1.0782 | valid acc : 84.58% | valid f1 score : 0.6552\n",
      "*** Epoch 6 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.97it/s]\n",
      "60it [00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train loss : 0.0872 | train acc : 98.25% valid loss : 0.7351 | valid acc : 87.22% | valid f1 score : 0.7161\n",
      "*** Epoch 7 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.97it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] train loss : 0.0564 | train acc : 99.13% valid loss : 1.2477 | valid acc : 86.14% | valid f1 score : 0.6891\n",
      "*** Epoch 8 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.92it/s]\n",
      "60it [00:11,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] train loss : 0.0394 | train acc : 99.37% valid loss : 1.1015 | valid acc : 87.33% | valid f1 score : 0.7044\n",
      "*** Epoch 9 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  4.00it/s]\n",
      "60it [00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] train loss : 0.0388 | train acc : 99.55% valid loss : 1.0878 | valid acc : 87.62% | valid f1 score : 0.7102\n",
      "*** Epoch 10 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  4.00it/s]\n",
      "60it [00:11,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] train loss : 0.0328 | train acc : 99.56% valid loss : 0.9798 | valid acc : 87.62% | valid f1 score : 0.7184\n",
      "*** Epoch 11 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  4.01it/s]\n",
      "60it [00:11,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] train loss : 0.0326 | train acc : 99.54% valid loss : 1.0961 | valid acc : 87.57% | valid f1 score : 0.7194\n",
      "*** Epoch 12 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.97it/s]\n",
      "60it [00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] train loss : 0.0303 | train acc : 99.66% valid loss : 1.1016 | valid acc : 86.61% | valid f1 score : 0.6946\n",
      "*** Epoch 13 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  4.00it/s]\n",
      "60it [00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] train loss : 0.0432 | train acc : 99.37% valid loss : 0.9927 | valid acc : 88.23% | valid f1 score : 0.7449\n",
      "*** Epoch 14 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.95it/s]\n",
      "60it [00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] train loss : 0.0726 | train acc : 98.51% valid loss : 0.9944 | valid acc : 84.76% | valid f1 score : 0.6862\n",
      "*** Epoch 15 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.94it/s]\n",
      "60it [00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] train loss : 0.1285 | train acc : 97.10% valid loss : 1.5957 | valid acc : 82.94% | valid f1 score : 0.6486\n",
      "*** Epoch 16 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [01:00,  3.94it/s]\n",
      "60it [00:11,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] train loss : 0.1397 | train acc : 96.69% valid loss : 1.8311 | valid acc : 82.96% | valid f1 score : 0.6378\n",
      "*** Epoch 17 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.95it/s]\n",
      "60it [00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] train loss : 0.1678 | train acc : 95.91% valid loss : 0.7651 | valid acc : 86.88% | valid f1 score : 0.7063\n",
      "*** Epoch 18 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237it [00:59,  3.97it/s]\n",
      "60it [00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] train loss : 0.1208 | train acc : 96.96% valid loss : 1.5816 | valid acc : 82.51% | valid f1 score : 0.6355\n",
      "*** Epoch 19 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:04,  3.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-e74bc5b9fbf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "best_f1 = 0\n",
    "early_stop_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('*** Epoch {} ***'.format(epoch))\n",
    "    \n",
    "    iter_train_loss = []\n",
    "    iter_valid_loss = []\n",
    "    iter_train_acc = []\n",
    "    iter_valid_acc = []\n",
    "    iter_valid_f1 = []\n",
    "\n",
    "    # Training\n",
    "    model.train()  \n",
    "        \n",
    "    for idx, (inputs, labels) in tqdm(enumerate(dataloaders_train)):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward\n",
    "      with torch.set_grad_enabled(True):\n",
    "        outputs= model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        iter_train_loss.append(loss.cpu().item())\n",
    "        train_pred_c = outputs.argmax(dim=-1)\n",
    "        iter_train_acc.extend((train_pred_c == labels).cpu().tolist())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  \n",
    "    \n",
    "    for idx, (inputs, labels) in tqdm(enumerate(dataloaders_valid)):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      with torch.set_grad_enabled(False):\n",
    "        outputs = model(inputs)\n",
    "        # statistics\n",
    "        valid_loss = criterion(outputs, labels)\n",
    "        iter_valid_loss.append(valid_loss.cpu().item())\n",
    "        valid_pred_c = outputs.argmax(dim=-1)\n",
    "        iter_valid_acc.extend((valid_pred_c == labels).cpu().tolist())\n",
    "        iter_f1_score = f1_score(y_true=labels.cpu().numpy(), y_pred=valid_pred_c.cpu().numpy(), average=\"macro\")\n",
    "        iter_valid_f1.append(iter_f1_score)\n",
    "\n",
    "    # statistics\n",
    "    epoch_train_loss = np.mean(iter_train_loss)\n",
    "    epoch_valid_loss = np.mean(iter_valid_loss)\n",
    "    epoch_train_acc = np.mean(iter_train_acc) * 100\n",
    "    epoch_valid_acc = np.mean(iter_valid_acc) * 100\n",
    "    epoch_valid_f1_score = np.mean(iter_valid_f1)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\n",
    "            f\"[Epoch {epoch}] \"\n",
    "            f\"train loss : {epoch_train_loss:.4f} | train acc : {epoch_train_acc:.2f}% \"\n",
    "            f\"valid loss : {epoch_valid_loss:.4f} | valid acc : {epoch_valid_acc:.2f}% | valid f1 score : {epoch_valid_f1_score:.4f}\"\n",
    "        )\n",
    "    \n",
    "    if epoch_valid_f1_score > best_f1:\n",
    "        best_f1 = epoch_valid_f1_score\n",
    "        best_model_state = model.state_dict()\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "\n",
    "    if early_stop_count == early_stop:\n",
    "        print(\"early stoped.\" + \" \" * 30)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5259b5d2-f4f9-492c-8555-be68253f34b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [03:09<00:00, 66.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(dataloaders_test):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        _, output = torch.max(pred, 1)\n",
    "        all_predictions.extend(output.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cf18df8-c524-4ebf-bff6-d6dff9658b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 192, 24, 24]         147,648\n",
      "          Identity-2             [-1, 576, 192]               0\n",
      "        PatchEmbed-3             [-1, 576, 192]               0\n",
      "           Dropout-4             [-1, 577, 192]               0\n",
      "         LayerNorm-5             [-1, 577, 192]             384\n",
      "            Linear-6             [-1, 577, 576]         111,168\n",
      "           Dropout-7          [-1, 3, 577, 577]               0\n",
      "            Linear-8             [-1, 577, 192]          37,056\n",
      "           Dropout-9             [-1, 577, 192]               0\n",
      "        Attention-10             [-1, 577, 192]               0\n",
      "         Identity-11             [-1, 577, 192]               0\n",
      "        LayerNorm-12             [-1, 577, 192]             384\n",
      "           Linear-13             [-1, 577, 768]         148,224\n",
      "             GELU-14             [-1, 577, 768]               0\n",
      "          Dropout-15             [-1, 577, 768]               0\n",
      "           Linear-16             [-1, 577, 192]         147,648\n",
      "          Dropout-17             [-1, 577, 192]               0\n",
      "              Mlp-18             [-1, 577, 192]               0\n",
      "         Identity-19             [-1, 577, 192]               0\n",
      "            Block-20             [-1, 577, 192]               0\n",
      "        LayerNorm-21             [-1, 577, 192]             384\n",
      "           Linear-22             [-1, 577, 576]         111,168\n",
      "          Dropout-23          [-1, 3, 577, 577]               0\n",
      "           Linear-24             [-1, 577, 192]          37,056\n",
      "          Dropout-25             [-1, 577, 192]               0\n",
      "        Attention-26             [-1, 577, 192]               0\n",
      "         Identity-27             [-1, 577, 192]               0\n",
      "        LayerNorm-28             [-1, 577, 192]             384\n",
      "           Linear-29             [-1, 577, 768]         148,224\n",
      "             GELU-30             [-1, 577, 768]               0\n",
      "          Dropout-31             [-1, 577, 768]               0\n",
      "           Linear-32             [-1, 577, 192]         147,648\n",
      "          Dropout-33             [-1, 577, 192]               0\n",
      "              Mlp-34             [-1, 577, 192]               0\n",
      "         Identity-35             [-1, 577, 192]               0\n",
      "            Block-36             [-1, 577, 192]               0\n",
      "        LayerNorm-37             [-1, 577, 192]             384\n",
      "           Linear-38             [-1, 577, 576]         111,168\n",
      "          Dropout-39          [-1, 3, 577, 577]               0\n",
      "           Linear-40             [-1, 577, 192]          37,056\n",
      "          Dropout-41             [-1, 577, 192]               0\n",
      "        Attention-42             [-1, 577, 192]               0\n",
      "         Identity-43             [-1, 577, 192]               0\n",
      "        LayerNorm-44             [-1, 577, 192]             384\n",
      "           Linear-45             [-1, 577, 768]         148,224\n",
      "             GELU-46             [-1, 577, 768]               0\n",
      "          Dropout-47             [-1, 577, 768]               0\n",
      "           Linear-48             [-1, 577, 192]         147,648\n",
      "          Dropout-49             [-1, 577, 192]               0\n",
      "              Mlp-50             [-1, 577, 192]               0\n",
      "         Identity-51             [-1, 577, 192]               0\n",
      "            Block-52             [-1, 577, 192]               0\n",
      "        LayerNorm-53             [-1, 577, 192]             384\n",
      "           Linear-54             [-1, 577, 576]         111,168\n",
      "          Dropout-55          [-1, 3, 577, 577]               0\n",
      "           Linear-56             [-1, 577, 192]          37,056\n",
      "          Dropout-57             [-1, 577, 192]               0\n",
      "        Attention-58             [-1, 577, 192]               0\n",
      "         Identity-59             [-1, 577, 192]               0\n",
      "        LayerNorm-60             [-1, 577, 192]             384\n",
      "           Linear-61             [-1, 577, 768]         148,224\n",
      "             GELU-62             [-1, 577, 768]               0\n",
      "          Dropout-63             [-1, 577, 768]               0\n",
      "           Linear-64             [-1, 577, 192]         147,648\n",
      "          Dropout-65             [-1, 577, 192]               0\n",
      "              Mlp-66             [-1, 577, 192]               0\n",
      "         Identity-67             [-1, 577, 192]               0\n",
      "            Block-68             [-1, 577, 192]               0\n",
      "        LayerNorm-69             [-1, 577, 192]             384\n",
      "           Linear-70             [-1, 577, 576]         111,168\n",
      "          Dropout-71          [-1, 3, 577, 577]               0\n",
      "           Linear-72             [-1, 577, 192]          37,056\n",
      "          Dropout-73             [-1, 577, 192]               0\n",
      "        Attention-74             [-1, 577, 192]               0\n",
      "         Identity-75             [-1, 577, 192]               0\n",
      "        LayerNorm-76             [-1, 577, 192]             384\n",
      "           Linear-77             [-1, 577, 768]         148,224\n",
      "             GELU-78             [-1, 577, 768]               0\n",
      "          Dropout-79             [-1, 577, 768]               0\n",
      "           Linear-80             [-1, 577, 192]         147,648\n",
      "          Dropout-81             [-1, 577, 192]               0\n",
      "              Mlp-82             [-1, 577, 192]               0\n",
      "         Identity-83             [-1, 577, 192]               0\n",
      "            Block-84             [-1, 577, 192]               0\n",
      "        LayerNorm-85             [-1, 577, 192]             384\n",
      "           Linear-86             [-1, 577, 576]         111,168\n",
      "          Dropout-87          [-1, 3, 577, 577]               0\n",
      "           Linear-88             [-1, 577, 192]          37,056\n",
      "          Dropout-89             [-1, 577, 192]               0\n",
      "        Attention-90             [-1, 577, 192]               0\n",
      "         Identity-91             [-1, 577, 192]               0\n",
      "        LayerNorm-92             [-1, 577, 192]             384\n",
      "           Linear-93             [-1, 577, 768]         148,224\n",
      "             GELU-94             [-1, 577, 768]               0\n",
      "          Dropout-95             [-1, 577, 768]               0\n",
      "           Linear-96             [-1, 577, 192]         147,648\n",
      "          Dropout-97             [-1, 577, 192]               0\n",
      "              Mlp-98             [-1, 577, 192]               0\n",
      "         Identity-99             [-1, 577, 192]               0\n",
      "           Block-100             [-1, 577, 192]               0\n",
      "       LayerNorm-101             [-1, 577, 192]             384\n",
      "          Linear-102             [-1, 577, 576]         111,168\n",
      "         Dropout-103          [-1, 3, 577, 577]               0\n",
      "          Linear-104             [-1, 577, 192]          37,056\n",
      "         Dropout-105             [-1, 577, 192]               0\n",
      "       Attention-106             [-1, 577, 192]               0\n",
      "        Identity-107             [-1, 577, 192]               0\n",
      "       LayerNorm-108             [-1, 577, 192]             384\n",
      "          Linear-109             [-1, 577, 768]         148,224\n",
      "            GELU-110             [-1, 577, 768]               0\n",
      "         Dropout-111             [-1, 577, 768]               0\n",
      "          Linear-112             [-1, 577, 192]         147,648\n",
      "         Dropout-113             [-1, 577, 192]               0\n",
      "             Mlp-114             [-1, 577, 192]               0\n",
      "        Identity-115             [-1, 577, 192]               0\n",
      "           Block-116             [-1, 577, 192]               0\n",
      "       LayerNorm-117             [-1, 577, 192]             384\n",
      "          Linear-118             [-1, 577, 576]         111,168\n",
      "         Dropout-119          [-1, 3, 577, 577]               0\n",
      "          Linear-120             [-1, 577, 192]          37,056\n",
      "         Dropout-121             [-1, 577, 192]               0\n",
      "       Attention-122             [-1, 577, 192]               0\n",
      "        Identity-123             [-1, 577, 192]               0\n",
      "       LayerNorm-124             [-1, 577, 192]             384\n",
      "          Linear-125             [-1, 577, 768]         148,224\n",
      "            GELU-126             [-1, 577, 768]               0\n",
      "         Dropout-127             [-1, 577, 768]               0\n",
      "          Linear-128             [-1, 577, 192]         147,648\n",
      "         Dropout-129             [-1, 577, 192]               0\n",
      "             Mlp-130             [-1, 577, 192]               0\n",
      "        Identity-131             [-1, 577, 192]               0\n",
      "           Block-132             [-1, 577, 192]               0\n",
      "       LayerNorm-133             [-1, 577, 192]             384\n",
      "          Linear-134             [-1, 577, 576]         111,168\n",
      "         Dropout-135          [-1, 3, 577, 577]               0\n",
      "          Linear-136             [-1, 577, 192]          37,056\n",
      "         Dropout-137             [-1, 577, 192]               0\n",
      "       Attention-138             [-1, 577, 192]               0\n",
      "        Identity-139             [-1, 577, 192]               0\n",
      "       LayerNorm-140             [-1, 577, 192]             384\n",
      "          Linear-141             [-1, 577, 768]         148,224\n",
      "            GELU-142             [-1, 577, 768]               0\n",
      "         Dropout-143             [-1, 577, 768]               0\n",
      "          Linear-144             [-1, 577, 192]         147,648\n",
      "         Dropout-145             [-1, 577, 192]               0\n",
      "             Mlp-146             [-1, 577, 192]               0\n",
      "        Identity-147             [-1, 577, 192]               0\n",
      "           Block-148             [-1, 577, 192]               0\n",
      "       LayerNorm-149             [-1, 577, 192]             384\n",
      "          Linear-150             [-1, 577, 576]         111,168\n",
      "         Dropout-151          [-1, 3, 577, 577]               0\n",
      "          Linear-152             [-1, 577, 192]          37,056\n",
      "         Dropout-153             [-1, 577, 192]               0\n",
      "       Attention-154             [-1, 577, 192]               0\n",
      "        Identity-155             [-1, 577, 192]               0\n",
      "       LayerNorm-156             [-1, 577, 192]             384\n",
      "          Linear-157             [-1, 577, 768]         148,224\n",
      "            GELU-158             [-1, 577, 768]               0\n",
      "         Dropout-159             [-1, 577, 768]               0\n",
      "          Linear-160             [-1, 577, 192]         147,648\n",
      "         Dropout-161             [-1, 577, 192]               0\n",
      "             Mlp-162             [-1, 577, 192]               0\n",
      "        Identity-163             [-1, 577, 192]               0\n",
      "           Block-164             [-1, 577, 192]               0\n",
      "       LayerNorm-165             [-1, 577, 192]             384\n",
      "          Linear-166             [-1, 577, 576]         111,168\n",
      "         Dropout-167          [-1, 3, 577, 577]               0\n",
      "          Linear-168             [-1, 577, 192]          37,056\n",
      "         Dropout-169             [-1, 577, 192]               0\n",
      "       Attention-170             [-1, 577, 192]               0\n",
      "        Identity-171             [-1, 577, 192]               0\n",
      "       LayerNorm-172             [-1, 577, 192]             384\n",
      "          Linear-173             [-1, 577, 768]         148,224\n",
      "            GELU-174             [-1, 577, 768]               0\n",
      "         Dropout-175             [-1, 577, 768]               0\n",
      "          Linear-176             [-1, 577, 192]         147,648\n",
      "         Dropout-177             [-1, 577, 192]               0\n",
      "             Mlp-178             [-1, 577, 192]               0\n",
      "        Identity-179             [-1, 577, 192]               0\n",
      "           Block-180             [-1, 577, 192]               0\n",
      "       LayerNorm-181             [-1, 577, 192]             384\n",
      "          Linear-182             [-1, 577, 576]         111,168\n",
      "         Dropout-183          [-1, 3, 577, 577]               0\n",
      "          Linear-184             [-1, 577, 192]          37,056\n",
      "         Dropout-185             [-1, 577, 192]               0\n",
      "       Attention-186             [-1, 577, 192]               0\n",
      "        Identity-187             [-1, 577, 192]               0\n",
      "       LayerNorm-188             [-1, 577, 192]             384\n",
      "          Linear-189             [-1, 577, 768]         148,224\n",
      "            GELU-190             [-1, 577, 768]               0\n",
      "         Dropout-191             [-1, 577, 768]               0\n",
      "          Linear-192             [-1, 577, 192]         147,648\n",
      "         Dropout-193             [-1, 577, 192]               0\n",
      "             Mlp-194             [-1, 577, 192]               0\n",
      "        Identity-195             [-1, 577, 192]               0\n",
      "           Block-196             [-1, 577, 192]               0\n",
      "       LayerNorm-197             [-1, 577, 192]             384\n",
      "        Identity-198                  [-1, 192]               0\n",
      "          Linear-199                   [-1, 18]           3,474\n",
      "================================================================\n",
      "Total params: 5,489,874\n",
      "Trainable params: 5,489,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 359.37\n",
      "Params size (MB): 20.94\n",
      "Estimated Total Size (MB): 382.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0352f2-6da8-4cbd-8a1a-1ef959457123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
